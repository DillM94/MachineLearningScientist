{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "seed = 231094"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning with XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost can be used for both supervised and unsupervised learning. \r\n",
    "- Supervised Classification/Regression\r\n",
    "    - ROCAUC for binary\r\n",
    "    - Accuracy, Confusion Matrix for multi\r\n",
    "- Decision Trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification with XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "breast_data = datasets.load_breast_cancer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X = breast_data.data\n",
    "y = breast_data.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = xgb.XGBClassifier(objective = 'binary:logistic', n_estimators = 10, seed = seed)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[10:28:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boosting with XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not exactly an algorithm. Its a meta-algorithm. Combines weak learners into much better learners by bringing them into one learner. \n",
    "- Accomplished by learning through weak learners. \n",
    "- Weighs each weak learner based on performance. \n",
    "- Combines those weighted predictions into a single prediciton. \n",
    "\n",
    "Cross-Validation is built into XGBoost\n",
    "\n",
    "- Use XGBoost for:\n",
    "    - Large number of trainign samples. Features < Samples\n",
    "    - Mixture of cat or numeric, or just numeric\n",
    "\n",
    "- Do not use for: \n",
    "    - Image, Comp Vision, NLP\n",
    "    - Not good for small training sets. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X, y\n",
    "\n",
    "breast_dmatrix = xgb.DMatrix(X, y) # Optimised data structure specific to XGB. When using xgb.cv we need to make this\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    'max_depth': 4\n",
    "} # xgb.cv won't know what model we're using. \n",
    "\n",
    "cv_results = xgb.cv(dtrain = breast_dmatrix, params = params, nfold = 4, num_boost_round = 10, metrics = 'error', as_pandas = True, seed = seed)\n",
    "\n",
    "cv_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024602</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>0.072060</td>\n",
       "      <td>0.012592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019922</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>0.017849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.054479</td>\n",
       "      <td>0.020143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.052706</td>\n",
       "      <td>0.018233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.043928</td>\n",
       "      <td>0.021899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.043916</td>\n",
       "      <td>0.020091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.038659</td>\n",
       "      <td>0.020215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>0.023331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.036898</td>\n",
       "      <td>0.017495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.040419</td>\n",
       "      <td>0.018874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.024602         0.007492         0.072060        0.012592\n",
       "1          0.019922         0.006740         0.063245        0.017849\n",
       "2          0.013470         0.006274         0.054479        0.020143\n",
       "3          0.011128         0.004177         0.052706        0.018233\n",
       "4          0.008785         0.003461         0.043928        0.021899\n",
       "5          0.005856         0.003512         0.043916        0.020091\n",
       "6          0.005856         0.003512         0.038659        0.020215\n",
       "7          0.005271         0.003041         0.042168        0.023331\n",
       "8          0.004684         0.003703         0.036898        0.017495\n",
       "9          0.004098         0.003042         0.040419        0.018874"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "1 - cv_results['test-error-mean'].iloc[-1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.95958075"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "auc_results = xgb.cv(dtrain = breast_dmatrix, params = params, nfold = 4, num_boost_round = 10, metrics = 'auc', as_pandas = True, seed = seed)\n",
    "auc_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991135</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.957643</td>\n",
       "      <td>0.010771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995277</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.968277</td>\n",
       "      <td>0.016443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997163</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.976878</td>\n",
       "      <td>0.015114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.981764</td>\n",
       "      <td>0.014424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999281</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.985923</td>\n",
       "      <td>0.011530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.999424</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.986485</td>\n",
       "      <td>0.011563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.986590</td>\n",
       "      <td>0.011375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.986459</td>\n",
       "      <td>0.011996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.988343</td>\n",
       "      <td>0.009552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.988173</td>\n",
       "      <td>0.009418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0        0.991135       0.007317       0.957643      0.010771\n",
       "1        0.995277       0.002559       0.968277      0.016443\n",
       "2        0.997163       0.002822       0.976878      0.015114\n",
       "3        0.999068       0.000871       0.981764      0.014424\n",
       "4        0.999281       0.000560       0.985923      0.011530\n",
       "5        0.999424       0.000488       0.986485      0.011563\n",
       "6        0.999675       0.000276       0.986590      0.011375\n",
       "7        0.999748       0.000199       0.986459      0.011996\n",
       "8        0.999822       0.000123       0.988343      0.009552\n",
       "9        0.999903       0.000057       0.988173      0.009418"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "auc_results['test-auc-mean'].iloc[-1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.98817275"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regession with XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regression problems are predicting real values.\n",
    "Metric is RMSE or MAE.\n",
    "Algorithms are usually linear regression or decision trees. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "boston_data = datasets.load_boston()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X = boston_data.data\n",
    "y = boston_data.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objective functions are hallmarks of regression algorithms. They quantify how far a prediciton is from the actual result. We try to minimise this function - to reduce loss. \n",
    "\n",
    "- reg:squarederror is for regression\n",
    "- reg:logistic is for classification (not probability)\n",
    "- binary:logistic is for classification (probability)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Using trees as base learners\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = seed)\n",
    "\n",
    "xg_tree = xgb.XGBRFRegressor(objective = 'reg:squarederror', n_estimators = 10, seed = seed)\n",
    "xg_tree.fit(X_train, y_train)\n",
    "y_preds = xg_tree.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_preds))\n",
    "rmse"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.811734401565331"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Using linear base learners\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = seed)\n",
    "\n",
    "train_DM = xgb.DMatrix(X_train, y_train)\n",
    "test_DM = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "params = {\n",
    "    'booster':'gblinear',\n",
    "    'objective':'reg:squarederror'\n",
    "}\n",
    "\n",
    "xg_reg = xgb.train(params = params, dtrain = train_DM, num_boost_round=10)\n",
    "y_preds = xg_reg.predict(test_DM)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_preds))\n",
    "rmse"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.017262505902363"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regularisation and Base Learners"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regularisation is a measure of model complexity. \n",
    "- gamma is for tree values. Minimum loss reduction allowed for a split to occur. \n",
    "- alpha is regularisation on leaf weights. High alpha drops large weights. L1.\n",
    "- lambda smoother than L1. Doesn't drop. L2. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Using L1\n",
    "boston_dm = xgb.DMatrix(X, y)\n",
    "\n",
    "params = {\n",
    "    'objective':'reg:squarederror',\n",
    "    'max_depth':4\n",
    "}\n",
    "\n",
    "l1_params = [1, 10, 100]\n",
    "rmse_l1 = []\n",
    "\n",
    "for l1 in l1_params:\n",
    "    params['alpha'] = l1\n",
    "    cv = xgb.cv(dtrain = boston_dm, params = params, nfold = 4, num_boost_round = 10, metrics = 'rmse', as_pandas = True, seed = seed)\n",
    "    rmse_l1.append(cv['test-rmse-mean'].tail(1).values[0])\n",
    "\n",
    "results = list(zip(l1_params, rmse_l1))\n",
    "pd.DataFrame(results, columns = ['l1', 'rmse'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.575130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3.742148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>4.739748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    l1      rmse\n",
       "0    1  3.575130\n",
       "1   10  3.742148\n",
       "2  100  4.739748"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting important Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "boston_dm\n",
    "params\n",
    "\n",
    "xg_model = xgb.train(dtrain = boston_dm, params = params, num_boost_round = 10)\n",
    "xgb.plot_importance(xg_model)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf0klEQVR4nO3de7xVdZ3/8ddbIOWOhFcQ8UoKiAqJTo5CpeEtteyCVqKWP0eL7CdlZqE2Uzp5w0Z/M3ml0qDyPul4STlpKZOgB0UZkhFUEG9442oc+Pz+2Ovo9ngOZ8HZe3/33ryfj8d+sNf1+/nAYX/OWmuv9VFEYGZm1p7NUgdgZma1wQXDzMxyccEwM7NcXDDMzCwXFwwzM8vFBcPMzHJxwTDLSdIPJF2bOg6zVOT7MKwSJC0EtgHWFs3ePSJe6uA+vx4Rf+xYdLVH0vnArhHxldSx2KbDRxhWSUdFRI+i10YXi1KQ1Dnl+BurVuO22ueCYUlJ6i3pOklLJC2W9C+SOmXLdpH0oKSlkl6XdJOkPtmyXwMDgf+UtFzS9ySNlrSoxf4XSvp09v58STdLulHSO8D49Y3fSqznS7oxez9IUkg6SdKLkt6UdJqkj0t6UtJbkq4s2na8pL9I+jdJb0v6H0mfKlq+vaQ7Jb0hab6kb7QYtzju04AfAF/Kcp+drXeSpLmSlkl6TtL/KdrHaEmLJJ0l6dUs35OKlneVdKmk57P4/iypa7Zsf0mPZDnNljR6I/6prQ64YFhqvwSagF2BfYBDga9nywRcCGwP7AHsAJwPEBFfBV7g/aOWn+Uc72jgZqAPcFM74+cxCtgN+BIwGTgX+DQwBPiipINbrPsc0A84D7hVUt9s2VRgUZbrccBPiwtKi7ivA34K/DbLfXi2zqvAkUAv4CTgckn7Fu1jW6A30B84BbhK0pbZskuAEcA/AH2B7wHrJPUH7gL+JZs/EbhF0lYb8HdkdcIFwyrp9uy31Lck3S5pG+Aw4MyIWBERrwKXA18GiIj5EXF/RLwbEa8BlwEHt737XB6NiNsjYh2FD9Y2x8/pnyNidUTcB6wApkbEqxGxGHiYQhFq9iowOSLWRMRvgXnAEZJ2AA4Ezs721QhcC3y1tbgjYlVrgUTEXRHxv1HwJ+A+4B+LVlkD/Dgb/25gOTBY0mbAycC3I2JxRKyNiEci4l3gK8DdEXF3Nvb9wEzg8A34O7I64XOhVknHFF+glrQf0AVYIql59mbAi9nyrYGfU/jQ65kte7ODMbxY9H7H9Y2f0ytF71e1Mt2jaHpxfPBbJs9TOKLYHngjIpa1WDayjbhbJekwCkcuu1PIoxvwVNEqSyOiqWh6ZRZfP2AL4H9b2e2OwBckHVU0rwswvb14rP64YFhKLwLvAv1afJA1uxAIYK+IWCrpGODKouUtv+K3gsKHJADZtYiWp06Kt2lv/FLrL0lFRWMgcCfwEtBXUs+iojEQWFy0bctcPzAtaXPgFuBrwB0RsUbS7RRO67XndWA1sAswu8WyF4FfR8Q3PrSVbXJ8SsqSiYglFE6bXCqpl6TNsgvdzaedelI4bfJWdi79uy128Qqwc9H034AtJB0hqQvwQ2DzDoxfalsDEyR1kfQFCtdl7o6IF4FHgAslbSFpLwrXGG5az75eAQZlp5MAPkIh19eApuxo49A8QWWn564HLssuvneSdEBWhG4EjpL0mWz+FtkF9AEbnr7VOhcMS+1rFD7snqFwuulmYLts2QXAvsDbFC683tpi2wuBH2bXRCZGxNvA6RTO/y+mcMSxiPVb3/il9t8ULpC/DvwEOC4ilmbLxgGDKBxt3Aacl10vaMvvsz+XSno8OzKZAPyOQh7HUzh6yWsihdNXjwFvAP8KbJYVs6MpfCvrNQpHHN/Fnx2bJN+4Z1YBksZTuMnwwNSxmG0s/5ZgZma5uGCYmVkuPiVlZma5+AjDzMxyqcn7MPr06RO77rpr6jDKYsWKFXTv3j11GGVRz7lBfefn3GpXc36zZs16PSI69EiXmiwY22yzDTNnzkwdRlk0NDQwevTo1GGURT3nBvWdn3OrXc35SXq+o/vyKSkzM8vFBcPMzHJxwTAzs1xcMMzMLBcXDDMzy8UFw8zMcnHBMDOzXFwwzMwsFxcMMzPLxQXDzMxyccEwM7NcXDDMzCwXFwwzszp38sknAwyXNKd5nqQvSHpa0jpJI/Psp2wFQ9IESXMl3SLpUUnvSppYtHwHSdOzdZ6W9O1yxWJmtikbP348wLMtZs8BPgc8lHc/5Xy8+enAYcAKYEfgmBbLm4CzIuJxST2BWZLuj4hnyhiTmdkm56CDDoLCZ+57BwkRMRdAUu79lKVgSPoPYGfgTuD6iLhc0hHF60TEEmBJ9n6ZpLlAf6DdgrFqzVoGff+u0gdeBc4a1sR451aT6jk/51Y6Cy86ov2VqlTZenpLWgiMjIjXs+nzgeURcUkr6w6icFg0NCLeaWN/pwKnAvTrt9WISZOvKUvcqW3TFV5ZlTqK8qjn3KC+83NupTOsf+/KDQYsX76cHj16MGbMmKeAzSJiaPFySQ3AxIhotytd8o57knoAtwBntlUsACLiauBqgIE77xqXPpU89LI4a1gTzq021XN+zq10Fp4wumJjQWk7Cib9CZDUhUKxuCkibs27XdcunZhXw4d169PQ0FDxH6hKqefcoL7zc24GCb9Wq8KVluuAuRFxWao4zMzq3bhx4wA+BgyWtEjSKZKOlbQIOAC4S9K97e2n7EcYkrYFZgK9gHWSzgT2BPYCvgo8JakxW/0HEXF3uWMyM9uUTJ06lWnTpj0ZES3vt7htQ/ZTtoIREYOKJge0ssqfgfzf5zIzs6R8p7eZmeXigmFmZrm4YJiZWS4uGGZmlosLhpmZ5eKCYWZmubhgmJlZLi4YZmaWiwuGmRlwxRVXMHToUIYMGcLkyZNTh1OVkhSMom58iyW9Lakxe01KEY+ZbdrmzJnDNddcw1//+ldmz57NH/7wB559tmWDOkt1hHE6cDhwAvBwROydvX6cKB4z24TNnTuX/fffn27dutG5c2cOPvhgbrttgx6ztEmo+OPNW3bj25h9uONebarn3KC+86v3rnRDhw7l3HPPZenSpXTt2pW7776bkSNbPqfPKl4wIuI0SWOBMcBQ4IeSZgMvUej69HSlYzKzTdsee+zB2WefzSGHHEKPHj0YPnw4nTvXZ8Oojihbi9b1Dpq1bwX+DqyLiOWSDgeuiIjd2tjGLVprXD3nBvWdXz23MW1uYVrsmmuuYauttuKYY46pWBzlUtSidVYrjzffMBFR8RewEOiXd37L1+677x71avr06alDKJt6zi2ivvPbFHJ75ZVXIiLi+eefj8GDB8cbb7yRMKrSac4PmBkd/OxO3aJ1W+CViAhJ+1G4CL80ZUxmtmn6/Oc/z9KlS+nSpQtXXXUVW265ZeqQqk7qk3THAf8kqQlYBXw5q4RmZhX18MMPpw6h6iUpGPF+N74rs5eZmVU53+ltZma5uGCYmVkuLhhmZpaLC4aZmeXigmFmZrm4YJiZWS4uGGZmlosLhpmZ5eKCYWZmubhgmFlVuvzyyxkyZAhDhw5l3LhxrF69OnVIm7zULVpvkvRzSfMlPSlp3xTxmFl1Wbx4MT//+c+ZOXMmc+bMYe3atUybNi11WJu8VA8fPB04DNgD+BawGzAK+Pfsz/Vyx73aVM+5QX3nN2Vs94qP2dTUxKpVq+jSpQsrV65k++23r3gM9kEVP8Jo0aL1NuBX2WPbZwB9JG1X6ZjMrLr079+fiRMnMnDgQLbbbjt69+7NoYcemjqsTV7qjntTgIsi4s/Z/AeAsyNiZivbuONejavn3KC+89upd6cPdaUrp2XLlnHeeecxadIkevTowfnnn8/BBx/MIYccUvKxWuu4V09K2XEvdT8MtTKv1QoWEVcDVwMM3HnXuPSp1KGXx1nDmnButame85sytjujR4+u2Hi///3v2Weffd5rkfrSSy8xY8aMssTQ0NBQ0dwqrZT5pf7pXgTsUDQ9AHipvY26dunEvIuOKFtQKTU0NLDwhNGpwyiLes4N6ju/hoaGio43cOBAZsyYwcqVK+natSsPPPAAI0d2rB21dVzqr9XeCXxNBfsDb0fEksQxmVlio0aN4rjjjmPfffdl2LBhrFu3jlNPPTV1WJu81EcYdwOHA/OBlcBJacMxs2pxwQUXcMEFF6QOw4qkbtEKcEaKGMzMbMOkPiVlZmY1wgXDzMxyccEwM7NcXDDMzCwXFwwzM8vFBcPMzHJxwTAzs1xcMMzMLBcXDDPLZd68eey9997vvXr16sXkyZNTh2UVlLzjXjb9cUlrJR2XIh4za9/gwYNpbGyksbGRWbNm0a1bN4499tjUYVkFJe24FxELJHUC/hW4N+/G7rhXm+o5N6hsfgsTP635gQceYJdddmHHHXdMGodVVsULRnHHPUnXU+h/cQvw8UrHYmYbZ9q0aYwbNy51GFZhqTvubQ78BvgkcB3wh4i4uY1t3HGvxtVzblDZ/Ib1712ZgTLFXenWrFnDcccdxw033EDfvn0rGkc5uONefqkfbz6ZQkvWtVJrzffe5457ta+ec4PK5lfpRk3FXdvuuOMORo0axec+97mKxlAu7riXX+r/vSOBaVmx6AccLqkpIm5f30buuFeb6jk3qP/8mk2dOtWnozZRSQtGROzU/F7SFAqnpG5PFpCZrdfKlSu5//77+cUvfpE6FEsg9RGGmdWQbt26sXTp0tRhWCLV0HGved74ykdiZmZ5+U5vMzPLxQXDzMxyccEwM7NcXDDMzCwXFwwzM8vFBcPMzHJxwTAzs1xcMMzMLBff6W1WQoMGDaJnz5506tSJzp07M3PmzNQhmZVM2Y4wirrq3SLpUUnvSprYYp2xkuZJmi/p++WKxaySpk+fTmNjo4uF1Z1yHmGcDhwGrAB2BI4pXph12rsKOARYBDwm6c6IeKa9HbvjXm2qdG6pu9KZ1ZtcRxiSdpG0efZ+dHb00Gc967/XVQ84ISIeA9a0WG0/YH5EPBcRfwemAUdvRA5mVUMShx56KCNGjODqq69OHY5ZSeU9wrgFGClpVwqd8e6k0Cnv8NZWjojTJI0FxkTE623ssz/wYtH0ImBUWwG06LjHpGFNOUOvLdt0LfwmXo8qnVtDQ0PFxoJCZ7OLL76Yfv368eabbzJx4kRWrVrF8OHDKxpHOSxfvrzif5+VUs+5QWnzy1sw1kVEk6RjgckR8W+Snujg2K212GuzX6w77tW+SueWoivdkUce+d707NmzWbNmTV10c6vnrnT1nBuk6bi3RtI44ETgqGxelw6OvQjYoWh6APBSng3dca821XNuAKtWrWLZsmX07NmTFStWcN999zFp0qTUYZmVTN6CcRJwGvCTiFggaSfgxg6O/RiwW7avxcCXgeM7uE+zZN58800OPPBAAJqamjj++OMZO3Zs4qjMSidXwYiIZySdDQzMphcAF+XZVtK2wEygF7BO0pnAnhHxjqRvAvcCnYDrI+LpDU/BrDpsv/32zJ49O3UYZmWTq2BIOgq4BPgIsJOkvYEfR8Rn29qmRVe9AW2sczdwd95gzcwsnbw37p1P4WuwbwFERCOwU1kiMjOzqpS3YDRFxNst5rX5jSYzM6s/eS96z5F0PNBJ0m7ABOCR8oVlZmbVJu8RxreAIcC7FG7Yexs4s0wxmZlZFWr3CCN75tOdEfFp4Nzyh2RmZtWo3SOMiFgLrJTUuwLxmJlZlcp7DWM18JSk+yk8fRaAiJhQlqjMzKzq5C0Yd2UvMzPbROW90/uX5Q7ErB64457Vs7x3ei+glfsuImLn9WwzAfgn4Blge2Bf4NyIuKRoneuBI4FXI2LohoVuVp2mT59Ov379UodhVnJ5T0mNLHq/BfAFoG8726y3415mCnAl8KuccQDuuFer3HHPrLblug8jIpYWvRZHxGTgk22tn7PjHhHxEPDGRkVuVoXccc/qWd5TUvsWTW5G4YijZ1vr5+y4t0Hcca/2ueNe7arnrnT1nBuk6bh3adH7JmAB8MWSRJCTO+7VPnfcq1313JWunnODNB33TomI54pnZI2PknDHvdpUz7mBO+5Z/ctbMG6m8C2nlvNGlDYcs9rljntW79ZbMCR9jMJDB3tL+lzRol4Uvi3VrnY67k0FRgP9JC0CzouI6zY4C7Mq4I57Vu/aO8IYTOE+iT7AUUXzlwHfWN+GOTvujWs3QjMzqwrrLRgRcQdwh6QDIuLRCsVkZmZVKO81jCcknUHh9NR7p6Ii4uSyRGVmZlUnbwOlXwPbAp8B/kThFNOycgVlZmbVJ2/B2DUifgSsyB5EeAQwrHxhmZlZtclbMJof6/GWpKFAb2BQWSIyM7OqlPcaxtWStgR+ROH5UD0A35FkZrYJydsP49rs7Z8oPFTQzMw2MblOSUnaRtJ1kv4rm95T0inlDc3MzKpJ3msYU4B7KTRCAvgbcGYZ4jErubVr17LPPvt84MGAZrbh8haMfhHxO2AdQEQ0AWs3dlBJEyTNlbRCUmP2miNpraT2GjOZbZArrriCPfbYI3UYZjUv70XvFZI+StamVdL+wNsdGPd04LCIWNA8Q9JRwHciot2GSu64V5umjO1e8TEXLVrEXXfdxbnnnstll11W8fHN6kneI4z/S+HbUbtI+guFlqrf2pgBi7vxSfpO0aJxwNSN2adZW84880x+9rOfsdlmeX/Uzawt7T2tdmBEvBARj0s6mMLDCAXMi4gPtVzNo7VufJK6AWOBb64nFnfcq3GV7mz26KOPsmbNGpYtW0ZjYyNLly4t6/j13LnNudWuSnbcu533+2D8NiI+X5JRP+wo4C/rOx3ljnu1b8rY7hXtbHbvvfcya9Ysxo8fz+rVq3nnnXe49tprufHGG8syXj13bnNutauSHfdU9L6c9198mQ04HeWOe7Wp0r/FXXjhhVx44YXvjX3JJZeUrViYbQraO7EbbbwvGUm9gYOBO8qxfzMzK432jjCGS3qHwpFG1+w92XRERK8SxHAscF9ErCjBvsxaNXr06Lo+7WBWCe01UOpUjkGLu/FFxBQKNwaamVkV83cNzcwsFxcMMzPLxQXDzMxyccEwM7NcXDDMzCwXFwwzM8vFBcPMzHJxwTAzs1xcMKyiVq9ezX777cfw4cMZMmQI5513XuqQzCynJAWjqONeSHoyez0iaXiKeKxyNt98cx588EFmz55NY2Mj99xzDzNmzEgdlpnlkOo52qcDhwHbAXMj4k1Jh1F4fPmoRDFZBUiiR48eAKxZs4Y1a9YgqZ2tzKwaVLxgFHfcA66PiEeyRTOAAXn24RatpbMwwWPi165dy4gRI5g/fz5nnHEGo0b5dwSzWqCIsjy1fP2DSguBkc0d97J5E4GPRcTX29imuOPeiEmTr6lEqBW3TVd4ZVXlxhvWv3fFxlq+fPl7RxfN0z/60Y+YMGECO+20U8XiKJeW+dUT51a7mvMbM2bMrIgY2ZF9VUVrN0ljgFOAA9taxx33yqOSzZpa6/w1a9Ysli5dykknnVSxOMqlnju3ObfaVcmOe2UnaS/gWuCwiFiaZxt33Ktdr732Gl26dKFPnz6sWrWKP/7xj5x99tmpwzKzHJIWDEkDgVuBr0bE31LGYpWxZMkSTjzxRNauXcu6dev44he/yJFHHpk6LDPLIfURxiTgo8D/y74p09TRc2xW3fbaay+eeOKJ1GGY2UZIUjCKOu59PXuZmVmV853eZmaWiwuGmZnl4oJhZma5uGCYmVkuLhhmZpaLC4aZmeXigmFmZrm4YJiZWS4uGFXo5JNPZuutt2bo0KGpQzEze0/qjnu3SfpPSbMlPS2p9h9ZWgLjx4/nnnvuSR2GmdkHpDrCOB04HHgMeCYihgOjgUslfSRRTFXjoIMOom/fvqnDMDP7gNQd934D9FThyYM9gDeApvb2UcmOeyk60pmZVaOkHfeAdykUjo8BPYEvRUSrlSBVx71KdqSD97tjvfzyy5xzzjnccMMNFR2/nDaVzmb1yLnVrnrquPcZoBH4JLALcL+khyPinZYrpuq4V+lmRs3dsRYuXEj37t3rqhOYO5vVLudWu+qp495JwEVROMyZL2kBhaONv65vo3ruuGdmVq1Sf632BeBTAJK2AQYDzyWNqAqMGzeOAw44gHnz5jFgwACuu+661CGZmSU/wvhnYIqkpwABZ0fE64ljSm7q1KmpQzAz+5DUHfcADk0Rg5mZbZjUp6TMzKxGuGCYmVkuLhhmZpaLC4aZmeXigmFmZrm4YJiZWS4uGGZmlosLhpmZ5eKCUYXccc/MqlHqjnu3SHpU0ruSJqaIpRq5456ZVaNUz5I6HTgMWAHsCByTKI6qdNBBB7Fw4cLUYZiZfUDqjnvXR8TlkjboWeXuuGdmVnkVLxgRcZqkscAYP5nWzKx2pH68eW4tWrQyaVi7rb9LoqGhoSLjNFu+fDkNDQ28/PLLrFixouLjl1NzbvWqnvNzbrWrlPnVTMEobtE6ePDg+NYJRyeOqDzcorV21XN+zq12lTI/f622CrnjnplVo6RHGJK2BWYCvYB1ks4E9oyId1LGlZo77plZNaqGjnsDUsRgZmYbxqekzMwsFxcMMzPLxQXDzMxyccEwM7NcXDDMzCwXFwwzM8vFBcPMzHJxwTAzs1xcMMzMLBcXjCrkFq1mVo1St2i9SdJoSY2Snpb0pxTxVBu3aDWzapS6ReubwCPA2Ih4QdLWeTau9457btFqZtUodYvWacCtEfECQES8Wul4zMwsH0VE5QeVFgIjgR8CXYAhQE/gioj4VRvbFHfcGzFp8jUViXVY/94VGafZ8uXL6dGjBy+//DLnnHMON9xwQ0XHL6fm3OpVPefn3GpXc35jxoyZFREjO7SziKj4C1gI9AOuBGYA3bPpZ4Hd29t+9913j3o1ffr0iIhYsGBBDBkyJG0wJdacW72q5/ycW+1qzg+YGR387E7donUR8HpErABWSHoIGA78LW1YZmbWUuqv1d4B/KOkzpK6AaOAuYljSs4tWs2sGiU9woiIuZLuAZ4E1gHXRsSclDFVA7doNbNqlLxFa0RcDFycIg4zM8sv9SkpMzOrES4YZmaWiwuGmZnl4oJhZma5uGCYmVkuLhhmZpaLC4aZmeXigmFmZrm4YJiZWS4uGGZmlosLhpmZ5eKCYWZmuSTpuNdRkpYB81LHUSb9gNdTB1Em9Zwb1Hd+zq12Nee3Y0Rs1ZEdpW6gtLHmRUdbDVYpSTOdW22q5/ycW+0qZX4+JWVmZrm4YJiZWS61WjCuTh1AGTm32lXP+Tm32lWy/GryoreZmVVerR5hmJlZhblgmJlZLjVVMCSNlTRP0nxJ308dT6lI2kHSdElzJT0t6dupYyoHSZ0kPSHpD6ljKSVJfSTdLOl/sn/DA1LHVCqSvpP9TM6RNFXSFqlj6ghJ10t6VdKconl9Jd0v6dnszy1Txrix2sjt4uzn8klJt0nq05ExaqZgSOoEXAUcBuwJjJO0Z9qoSqYJOCsi9gD2B86oo9yKfRuYmzqIMrgCuCciPgYMp05ylNQfmACMjIihQCfgy2mj6rApwNgW874PPBARuwEPZNO1aAofzu1+YGhE7AX8DTinIwPUTMEA9gPmR8RzEfF3YBpwdOKYSiIilkTE49n7ZRQ+cPqnjaq0JA0AjgCuTR1LKUnqBRwEXAcQEX+PiLeSBlVanYGukjoD3YCXEsfTIRHxEPBGi9lHA7/M3v8SOKaSMZVKa7lFxH0R0ZRNzgAGdGSMWioY/YEXi6YXUWcfqgCSBgH7AP+dOJRSmwx8D1iXOI5S2xl4DbghO912raTuqYMqhYhYDFwCvAAsAd6OiPvSRlUW20TEEij88gZsnTiecjkZ+K+O7KCWCoZamVdX3wmW1AO4BTgzIt5JHU+pSDoSeDUiZqWOpQw6A/sC/x4R+wArqN1TGh+Qncs/GtgJ2B7oLukraaOyjSHpXAqnvm/qyH5qqWAsAnYomh5AjR8eF5PUhUKxuCkibk0dT4l9AvispIUUTiV+UtKNaUMqmUXAoohoPiK8mUIBqQefBhZExGsRsQa4FfiHxDGVwyuStgPI/nw1cTwlJelE4EjghOjgjXe1VDAeA3aTtJOkj1C4+HZn4phKQpIonAOfGxGXpY6n1CLinIgYEBGDKPy7PRgRdfGbakS8DLwoaXA261PAMwlDKqUXgP0ldct+Rj9FnVzQb+FO4MTs/YnAHQljKSlJY4Gzgc9GxMqO7q9mCkZ24eabwL0Ufmh/FxFPp42qZD4BfJXCb96N2evw1EFZbt8CbpL0JLA38NO04ZRGdtR0M/A48BSFz4uafoyGpKnAo8BgSYsknQJcBBwi6VngkGy65rSR25VAT+D+7HPlPzo0hh8NYmZmedTMEYaZmaXlgmFmZrm4YJiZWS4uGGZmlosLhpmZ5dI5dQBm1ULSWgpfH212TEQsTBSOWdXx12rNMpKWR0SPCo7XuejBcGZVz6ekzHKStJ2kh7IboOZI+sds/lhJj0uaLemBbF5fSbdnfQhmSNorm3++pKsl3Qf8StJWkm6R9Fj2+kTCFM3Wy6ekzN7XVVJj9n5BRBzbYvnxwL0R8ZOsP0s3SVsB1wAHRcQCSX2zdS8AnoiIYyR9EvgVhbvAAUYAB0bEKkm/AS6PiD9LGkjhSQZ7lC1Dsw5wwTB736qI2Hs9yx8Drs8eFHl7RDRKGg08FBELACKiuR/BgcDns3kPSvqopN7ZsjsjYlX2/tPAnoVHNQHQS1LPrC+KWVVxwTDLKSIeknQQhUZQv5Z0MfAWrT9mf32P419RNG8z4ICiAmJWtXwNwywnSTtS6OtxDYWnC+9L4WFvB0vaKVun+ZTUQ8AJ2bzRwOtt9Di5j8JDNZvH2LtM4Zt1mI8wzPIbDXxX0hpgOfC1iHhN0qnArZI2o9BL4RDgfApd+J4EVvL+47NbmgBcla3XmUKhOa2sWZhtJH+t1szMcvEpKTMzy8UFw8zMcnHBMDOzXFwwzMwsFxcMMzPLxQXDzMxyccEwM7Nc/j9U+Uu0p1C3/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine Tuning and XGBoost Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why should we tune? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "X, y, boston_dm"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " <xgboost.core.DMatrix at 0x7f86d82a2d90>)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Untuned\n",
    "params = {\n",
    "    'objective':'reg:squarederror'\n",
    "}\n",
    "untuned_model = xgb.cv(dtrain = boston_dm, params = params, nfold = 4, metrics = 'rmse', as_pandas = True, seed = seed)\n",
    "untuned_model['test-rmse-mean'].tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9    3.518716\n",
       "Name: test-rmse-mean, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Tuned\n",
    "params = {\n",
    "    'objective':'reg:squarederror',\n",
    "    'colsample_bytree':0.4,\n",
    "    'learning_rate':0.1,\n",
    "    'max_depth':5\n",
    "}\n",
    "tuned_model = xgb.cv(dtrain=boston_dm, params = params, nfold = 4, num_boost_round = 200, metrics = 'rmse', as_pandas = True, seed = seed)\n",
    "tuned_model['test-rmse-mean'].tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "199    3.387753\n",
       "Name: test-rmse-mean, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# With early stopping\n",
    "stop_model = xgb.cv(dtrain=boston_dm, params = params, nfold = 4, num_boost_round = 200, early_stopping_rounds = 10, metrics = 'rmse', as_pandas = True, seed = seed)\n",
    "stop_model['test-rmse-mean'].tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "105    3.386671\n",
       "Name: test-rmse-mean, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Tree based:\n",
    "    - learning_rate: How quickly the model fits residual error\n",
    "    - gamma, alpha, lambda: Regularisation\n",
    "    - max_depth: How deep each tree can grow per round\n",
    "    - subsample: 0-1, How many samples of training data can be used per tree\n",
    "    - colsample_bytree: 0-1, How many features can be used per tree\n",
    "\n",
    "- Linear Based:\n",
    "    - alpha, lambda, lambda-bias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Learning Rate\n",
    "X, y, boston_dm\n",
    "\n",
    "lr_vals = [0.001, 0.01, 0.1]\n",
    "rmse_vals = []\n",
    "params = {\n",
    "    'objective':'reg:squarederror',\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "for lr in lr_vals:\n",
    "    params['learning_rate'] = lr\n",
    "    model = xgb.cv(\n",
    "        dtrain = boston_dm,\n",
    "        params = params,\n",
    "        early_stopping_rounds = 10,\n",
    "        nfold = 3,\n",
    "        num_boost_round = 10,\n",
    "        as_pandas = True,\n",
    "        metrics = 'rmse',\n",
    "        seed = seed\n",
    "    )\n",
    "    rmse_vals.append(model['test-rmse-mean'].tail(1).values[-1])\n",
    "\n",
    "pd.DataFrame(list(zip(lr_vals, rmse_vals)), columns=['Learning Rate', 'Error'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>23.642105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>21.721801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>9.375521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate      Error\n",
       "0          0.001  23.642105\n",
       "1          0.010  21.721801\n",
       "2          0.100   9.375521"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Tuning max_depth\n",
    "X, y, boston_dm\n",
    "\n",
    "params = {\n",
    "    'objective':'reg:squarederror'\n",
    "}\n",
    "depths = [2, 5, 10, 20]\n",
    "rmse_vals = []\n",
    "\n",
    "for depth in depths: \n",
    "    params['max_depth'] = depth\n",
    "    model = xgb.cv(\n",
    "        dtrain = boston_dm,\n",
    "        params = params,\n",
    "        early_stopping_rounds = 10,\n",
    "        nfold = 3,\n",
    "        num_boost_round = 10,\n",
    "        as_pandas = True,\n",
    "        metrics = 'rmse',\n",
    "        seed = seed\n",
    "    )\n",
    "    rmse_vals.append(model['test-rmse-mean'].tail(1).values[-1])\n",
    "\n",
    "pd.DataFrame(list(zip(depths, rmse_vals)), columns = ['Depth', 'Error'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4.126482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3.622287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3.693062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>3.706704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth     Error\n",
       "0      2  4.126482\n",
       "1      5  3.622287\n",
       "2     10  3.693062\n",
       "3     20  3.706704"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Can also use GridSearch and RandomSearch with XGBoost!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Grid Search\n",
    "X, y, boston_dm\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate':[0.01, 0.03, 0.1, 0.3],\n",
    "    'n_estimators':[100, 200],\n",
    "    'subsample':[0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRFRegressor()\n",
    "grid_model = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'neg_mean_squared_error')\n",
    "grid_model.fit(X, y)\n",
    "print('Best Parameters', grid_model.best_params_)\n",
    "print('Lowest RMSE', np.sqrt(np.abs(grid_model.best_score_)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Parameters {'learning_rate': 0.3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Lowest RMSE 17.080337446009906\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Random Search\n",
    "X, y, boston_dm\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate':[0.01, 0.03, 0.1, 0.3],\n",
    "    'n_estimators':[100, 200],\n",
    "    'subsample':[0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRFRegressor()\n",
    "grid_model = RandomizedSearchCV(estimator = model, param_distributions = param_grid, scoring = 'neg_mean_squared_error', n_iter = 25)\n",
    "grid_model.fit(X, y)\n",
    "print('Best Parameters', grid_model.best_params_)\n",
    "print('Lowest RMSE', np.sqrt(np.abs(grid_model.best_score_)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 24 is smaller than n_iter=25. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Parameters {'subsample': 0.5, 'n_estimators': 100, 'learning_rate': 0.3}\n",
      "Lowest RMSE 17.080337446009906\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipelines and XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "X, y\n",
    "\n",
    "steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor())\n",
    "]\n",
    "\n",
    "rf_pipe = Pipeline(steps)\n",
    "\n",
    "scores = cross_val_score(rf_pipe, X, y, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "rmse = np.mean(np.sqrt(np.abs(scores)))\n",
    "rmse # Off by four units"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.233548610447237"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One issue with pipelines is we can't use a label encoder or OneHotEncoding with the pipeline.\n",
    "It must be done before the pipeline begins. We can use a DictVectorizer instead. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "dv = DictVectorizer(sparse = False)\n",
    "X_dict = pd.DataFrame(X).to_dict('records') # Must first be converted from a df to a dict\n",
    "dv.fit_transform(X_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# To use xgboost\n",
    "\n",
    "steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('xgb_model', xgb.XGBRFRegressor()) # Only difference!\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}