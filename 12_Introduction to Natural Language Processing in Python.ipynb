{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "seed = 231094"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regular Expressions and Word Tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to Regular Expressions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regular expressions are strings with special syntax that allow us to find particular patterns in strings. \n",
    "- Find links. \n",
    "- Parse email addresses.\n",
    "- Remove unwanted characters. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# To check a match between two strings.\n",
    "re.match('abcd', 'abcd')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abcd'>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "re.match('Dill', 'Dillon')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='Dill'>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Match with the first word. \n",
    "re.match('\\w+', 'First word')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='First'>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Match on the firs letter. Note the absence of +.\n",
    "re.match('\\w', 'first letter')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='f'>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Match with the first digit.\n",
    "re.match('\\d', '923')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='9'>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Match with the first space.\n",
    "re.match('\\s', ' a b c ')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match=' '>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "re.match('[a-z]+', 'hello')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='hello'>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Search will check the entire string.\n",
    "re.search('Dillon', 'Hello Dillon')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<re.Match object; span=(6, 12), match='Dillon'>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# To split on the spaces.\n",
    "re.split('\\s', 'Split on the spaces.')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Split', 'on', 'the', 'spaces.']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to Tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenization is transforming a string or document into smaller chunks. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Tokenizing on words.\n",
    "word_tokenize('Hello my name is Dillon!')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello', 'my', 'name', 'is', 'Dillon', '!']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Tokenizing on sentences.\n",
    "sent_tokenize('Sometimes to understand a word\\'s meaning you need more than a definition; you need to see the word used in a sentence. At YourDictionary, we give you the tools to learn what a word means and how to use it correctly. With this sentence maker, simply type a word in the search bar and see a variety of sentences with that word used in its different ways. Our sentence generator can provide more context and relevance, ensuring you use a word the right way.')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"Sometimes to understand a word's meaning you need more than a definition; you need to see the word used in a sentence.\",\n",
       " 'At YourDictionary, we give you the tools to learn what a word means and how to use it correctly.',\n",
       " 'With this sentence maker, simply type a word in the search bar and see a variety of sentences with that word used in its different ways.',\n",
       " 'Our sentence generator can provide more context and relevance, ensuring you use a word the right way.']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Tokeniizng on unique words.\n",
    "set(word_tokenize('Here is a sentence with a few common words. Like this one here, and that sentence there.'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{',',\n",
       " '.',\n",
       " 'Here',\n",
       " 'Like',\n",
       " 'a',\n",
       " 'and',\n",
       " 'common',\n",
       " 'few',\n",
       " 'here',\n",
       " 'is',\n",
       " 'one',\n",
       " 'sentence',\n",
       " 'that',\n",
       " 'there',\n",
       " 'this',\n",
       " 'with',\n",
       " 'words'}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Tokenization with Regex"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Groups can be made using () or ranges using []"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "match_digits_and_words = ('(\\d+|\\w+)')\n",
    "re.findall(match_digits_and_words, 'He has 11 cats.')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['He', 'has', '11', 'cats']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "re.findall('[a-z]', 'abcd')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "re.findall('(a|b|c)', 'abcd')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "re.findall('\\-|\\.', 'www.my-site.com')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['.', '-', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Matplotlib"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "sentence = 'This is a pretty cool tool!'\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "word_lens = [len(s) for s in words]\n",
    "plt.hist(word_lens)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([2., 0., 1., 0., 0., 0., 3., 0., 0., 1.]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Topic Identification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bag-of-words is a simple method for identifying topics. Need to tokenize a word, then count those words. The more frequent a word the easier it is to indentify the theme. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "sentence = 'The cat is in the box. The cat likes the box. The box is over the cat.'\n",
    "counter = Counter(word_tokenize(sentence))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "counter"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'The': 3,\n",
       "         'cat': 3,\n",
       "         'is': 2,\n",
       "         'in': 1,\n",
       "         'the': 3,\n",
       "         'box': 3,\n",
       "         '.': 3,\n",
       "         'likes': 1,\n",
       "         'over': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "counter.most_common(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('The', 3), ('cat', 3)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Text Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "text = 'The cat is in the box. The cat likes the box. The box is over the cat.'\n",
    "\n",
    "tokens = [w for w in word_tokenize(text.lower()) if w.isalpha()]\n",
    "no_stops = [t for t in tokens if t not in stopwords.words('english')]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['the',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'likes',\n",
       " 'the',\n",
       " 'box',\n",
       " 'the',\n",
       " 'box',\n",
       " 'is',\n",
       " 'over',\n",
       " 'the',\n",
       " 'cat']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "Counter(tokens).most_common(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the', 6), ('cat', 3)]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "no_stops"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['cat', 'box', 'cat', 'likes', 'box', 'box', 'cat']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "Counter(no_stops).most_common(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('cat', 3), ('box', 3)]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Named Entity Recognition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A method to indetify the who, what, where, when and why of text. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "article = '''Albert Einstein was born in Ulm, \n",
    "in the Kingdom of Württemberg in the German Empire, \n",
    "on 14 March 1879 into a family of secular Ashkenazi Jews.\n",
    "His parents were Hermann Einstein, a salesman and engineer, and Pauline Koch. \n",
    "In 1880, the family moved to Munich, where Einstein's father and his uncle \n",
    "Jakob founded Elektrotechnische Fabrik J. Einstein & Cie, a company that \n",
    "manufactured electrical equipment based on direct current.'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "sentences = sent_tokenize(article)\n",
    "token_sentences = [word_tokenize(w) for w in sentences]\n",
    "pos_sentences = [nltk.pos_tag(w) for w in token_sentences]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "pos_sentences"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[('Albert', 'NNP'),\n",
       "  ('Einstein', 'NNP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('born', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('Ulm', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('Kingdom', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Württemberg', 'NNP'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('German', 'JJ'),\n",
       "  ('Empire', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('on', 'IN'),\n",
       "  ('14', 'CD'),\n",
       "  ('March', 'NNP'),\n",
       "  ('1879', 'CD'),\n",
       "  ('into', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('family', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('secular', 'JJ'),\n",
       "  ('Ashkenazi', 'NNP'),\n",
       "  ('Jews', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('His', 'PRP$'),\n",
       "  ('parents', 'NNS'),\n",
       "  ('were', 'VBD'),\n",
       "  ('Hermann', 'NNP'),\n",
       "  ('Einstein', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('a', 'DT'),\n",
       "  ('salesman', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('engineer', 'NN'),\n",
       "  (',', ','),\n",
       "  ('and', 'CC'),\n",
       "  ('Pauline', 'NNP'),\n",
       "  ('Koch', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('In', 'IN'),\n",
       "  ('1880', 'CD'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('family', 'NN'),\n",
       "  ('moved', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('Munich', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('where', 'WRB'),\n",
       "  ('Einstein', 'NNP'),\n",
       "  (\"'s\", 'POS'),\n",
       "  ('father', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('uncle', 'NN'),\n",
       "  ('Jakob', 'NNP'),\n",
       "  ('founded', 'VBD'),\n",
       "  ('Elektrotechnische', 'NNP'),\n",
       "  ('Fabrik', 'NNP'),\n",
       "  ('J.', 'NNP'),\n",
       "  ('Einstein', 'NNP'),\n",
       "  ('&', 'CC'),\n",
       "  ('Cie', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('a', 'DT'),\n",
       "  ('company', 'NN'),\n",
       "  ('that', 'WDT'),\n",
       "  ('manufactured', 'VBD'),\n",
       "  ('electrical', 'JJ'),\n",
       "  ('equipment', 'NN'),\n",
       "  ('based', 'VBN'),\n",
       "  ('on', 'IN'),\n",
       "  ('direct', 'JJ'),\n",
       "  ('current', 'JJ'),\n",
       "  ('.', '.')]]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary = True)\n",
    "for sent in chunked_sentences:\n",
    "    for chunk in sent:\n",
    "        if hasattr(chunk, 'label') and chunk.label() == 'NE': # Named Entity\n",
    "            print(chunk)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(NE Albert/NNP Einstein/NNP)\n",
      "(NE Ulm/NNP)\n",
      "(NE Württemberg/NNP)\n",
      "(NE German/JJ Empire/NNP)\n",
      "(NE Ashkenazi/NNP Jews/NNP)\n",
      "(NE Hermann/NNP Einstein/NNP)\n",
      "(NE Pauline/NNP Koch/NNP)\n",
      "(NE Munich/NNP)\n",
      "(NE Einstein/NNP)\n",
      "(NE Jakob/NNP)\n",
      "(NE Elektrotechnische/NNP Fabrik/NNP J./NNP Einstein/NNP)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Fake News Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "news = pd.read_csv('/Users/Dillon/OneDrive/Documents/DataCampML/fake_or_real_news.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "news.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "y = news['label']\n",
    "X = news['text']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using CountVectorizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "count_vec = CountVectorizer(stop_words='english')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "count_train = count_vec.fit_transform(X_train)\n",
    "count_test = count_vec.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns = count_vec.get_feature_names())\n",
    "count_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>0002</th>\n",
       "      <th>000billion</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000x</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>...</th>\n",
       "      <th>تنجح</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57597 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000031  0002  000billion  000ft  000x  001  002  ...  \\\n",
       "0   0    0     0         0     0           0      0     0    0    0  ...   \n",
       "1   0    0     0         0     0           0      0     0    0    0  ...   \n",
       "2   0    1     0         0     0           0      0     0    0    0  ...   \n",
       "3   0    0     0         0     0           0      0     0    0    0  ...   \n",
       "4   0    0     0         0     0           0      0     0    0    0  ...   \n",
       "\n",
       "   تنجح  حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  \n",
       "0     0    0     0   0   0   0        0   0    0        0  \n",
       "1     0    0     0   0   0   0        0   0    0        0  \n",
       "2     0    0     0   0   0   0        0   0    0        0  \n",
       "3     0    0     0   0   0   0        0   0    0        0  \n",
       "4     0    0     0   0   0   0        0   0    0        0  \n",
       "\n",
       "[5 rows x 57597 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "nav_b = MultinomialNB()\n",
    "nav_b.fit(count_train, y_train)\n",
    "y_preds = nav_b.predict(count_test)\n",
    "metrics.accuracy_score(y_test, y_preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9042609153077328"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "metrics.confusion_matrix(y_test, y_preds, labels = ['FAKE', 'REAL'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[808, 108],\n",
       "       [ 74, 911]])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using TfidfVectorizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', max_df = 0.7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "tfidf_train = tfidf_vec.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vec.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns = tfidf_vec.get_feature_names())\n",
    "tfidf_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>0002</th>\n",
       "      <th>000billion</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000x</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>...</th>\n",
       "      <th>تنجح</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57597 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00       000  0000  00000031  0002  000billion  000ft  000x  001  002  \\\n",
       "0  0.0  0.000000   0.0       0.0   0.0         0.0    0.0   0.0  0.0  0.0   \n",
       "1  0.0  0.000000   0.0       0.0   0.0         0.0    0.0   0.0  0.0  0.0   \n",
       "2  0.0  0.034606   0.0       0.0   0.0         0.0    0.0   0.0  0.0  0.0   \n",
       "3  0.0  0.000000   0.0       0.0   0.0         0.0    0.0   0.0  0.0  0.0   \n",
       "4  0.0  0.000000   0.0       0.0   0.0         0.0    0.0   0.0  0.0  0.0   \n",
       "\n",
       "   ...  تنجح  حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  \n",
       "0  ...   0.0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0  \n",
       "1  ...   0.0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0  \n",
       "2  ...   0.0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0  \n",
       "3  ...   0.0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0  \n",
       "4  ...   0.0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 57597 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "nav_b.fit(tfidf_train, y_train)\n",
    "y_preds = nav_b.predict(tfidf_test)\n",
    "metrics.accuracy_score(y_test, y_preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8542872172540767"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "metrics.confusion_matrix(y_test, y_preds, labels = ['FAKE', 'REAL'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[662, 254],\n",
       "       [ 23, 962]])"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}